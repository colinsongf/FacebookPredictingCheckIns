{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('data/train.csv')\n",
    "dfTest = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     8523065625\n",
      "1     1757726713\n",
      "2     1137537235\n",
      "3     6567393236\n",
      "4     7440663949\n",
      "5     6289802927\n",
      "6     9931249544\n",
      "7     5662813655\n",
      "8     8471780938\n",
      "9     1253803156\n",
      "10    8684462954\n",
      "11    2159916487\n",
      "12    7652380351\n",
      "13    8234363596\n",
      "14    2272949794\n",
      "15    4740742194\n",
      "16    2123587484\n",
      "17    8016758016\n",
      "18    8936085695\n",
      "19    2778700985\n",
      "Name: place_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#predictors = ['x', 'y', 'accuracy', 'time']\n",
    "#X = dfTrain[predictors]\n",
    "#y = dfTrain.place_id\n",
    "#dump_svmlight_file(X, y,'data/train.libfm',zero_based=True,multilabel=False)\n",
    "#len(dfTrain.place_id.unique())\n",
    "print dfTrain.place_id.head(20) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictLabelIndex = {}\n",
    "def genLabel(lstLabel):\n",
    "    # The lalel need to be 0 to num_class - 1\n",
    "    index = 0\n",
    "    for label in lstLabel:\n",
    "        if not dictLabelIndex.has_key(label):\n",
    "            dictLabelIndex[label] = index\n",
    "            index += 1\n",
    "    lstIndex = []\n",
    "    for label in lstLabel:\n",
    "        index = dictLabelIndex[label]\n",
    "        lstIndex.append(index)\n",
    "    return lstIndex\n",
    "\n",
    "def getLabel(lstLabel):\n",
    "    lstIndex = []\n",
    "    for label in lstLabel:\n",
    "        if dictLabelIndex.has_key(label):\n",
    "            index = dictLabelIndex[label]\n",
    "        else:\n",
    "            index = 0\n",
    "        lstIndex.append(index)\n",
    "    return lstIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# label need to be 0 to num_class -1\n",
    "data = np.loadtxt('data/train.csv.100000', delimiter=',',skiprows = 1, \n",
    "                  converters={})\n",
    "\n",
    "sz = data.shape\n",
    "\n",
    "print len(set(data[:, 5]))\n",
    "\n",
    "genLabel(data[:, 5])\n",
    "#print 'dictLabelIndex', dictLabelIndex\n",
    "\n",
    "train = data[:int(len(data) * 0.7), :]\n",
    "test = data[int(len(data) * 0.7):, :]\n",
    "\n",
    "train_X = train[:,1:5]\n",
    "train_Y = np.array(getLabel(train[:, 5]))\n",
    "print 'train_Y', train_Y\n",
    "print 'train_X', train_X\n",
    "#print train_Y\n",
    "\n",
    "test_X = test[:,1:5]\n",
    "test_Y = np.array(getLabel(test[:, 5]))\n",
    "\n",
    "xg_train = xgb.DMatrix( train_X, label = train_Y)\n",
    "xg_test = xgb.DMatrix(test_X, label = test_Y)\n",
    "num_class = len(set(data[:, 5]))\n",
    "print 'num_class', num_class\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = num_class\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 5\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "pred = bst.predict( xg_test );\n",
    "\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))\n",
    "\n",
    "# do the same thing again, but output probabilities\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "yprob = bst.predict( xg_test ).reshape( test_Y.shape[0],  num_class)\n",
    "ylabel = np.argmax(yprob, axis=1)\n",
    "\n",
    "#import ml_metrics as metrics\n",
    "#target = [[l] for l in t2[\"hotel_cluster\"]]\n",
    "#metrics.mapk(target, predictions, k=5)\n",
    "print ('predicting, classification error=%f' % (sum( int(ylabel[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
